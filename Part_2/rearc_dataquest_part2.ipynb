{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ec939a8",
   "metadata": {},
   "source": [
    "# Rearc Data Quest - Part 2\n",
    "\n",
    "## What this notebook does -\n",
    "1. **Fetch the payload** from DataUSA API using the `tesseract/data.jsonrecords` endpoint with `drilldowns=Year,Nation` & `measures=Population`.  \n",
    "2. **Do not reshape or aggregate** the JSON. We upload **exactly** what the API returns.  \n",
    "3. **Write the exact JSON** to `population_data.json` locally and then **PUT the same bytes** to S3.  \n",
    "4. **Validations** (optional) to catch mistakes (e.g., verify `Year` appears in `columns`, `data` has >1 row).\n",
    "\n",
    "> Set your AWS credentials in the environment (or credentials file) and update `BUCKET_NAME` and `OBJECT_KEY` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e848c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import os, json, sys, time\n",
    "from typing import Dict, Any\n",
    "import requests\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5900569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "API_URL = \"https://honolulu-api.datausa.io/tesseract/data.jsonrecords?cube=acs_yg_total_population_1&drilldowns=Year%2CNation&locale=en&measures=Population\"\n",
    "API_PARAMS = {\n",
    "    \"cube\": \"acs_yg_total_population_1\",\n",
    "    \"drilldowns\": \"Year,Nation\",\n",
    "    \"locale\": \"en\",\n",
    "    \"measures\": \"Population\"\n",
    "}\n",
    "\n",
    "# >>>> EDIT THESE if needed <<<<\n",
    "BUCKET_NAME = os.getenv(\"REARC_DQ_BUCKET\", \"rearc-dataquest-harpreet\")  # change if needed\n",
    "OBJECT_KEY  = \"part2/population_data.json\"                              # path in S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8265226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns: ['Nation ID', 'Nation', 'Year', 'Population']\n",
      "data rows: 10\n",
      "sample: [{'Nation ID': '01000US', 'Nation': 'United States', 'Year': 2013, 'Population': 316128839.0}, {'Nation ID': '01000US', 'Nation': 'United States', 'Year': 2014, 'Population': 318857056.0}]\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Fetch the payload (Year,Nation drilldowns) ---\n",
    "def fetch_population_payload() -> Dict[str, Any]:\n",
    "    resp = requests.get(API_URL, params=API_PARAMS, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()\n",
    "\n",
    "payload = fetch_population_payload()\n",
    "\n",
    "# Pretty-print a short preview for sanity (first 2 data rows if present)\n",
    "print(\"columns:\", payload.get(\"columns\", []) )\n",
    "print(\"data rows:\", len(payload.get(\"data\", [])))\n",
    "print(\"sample:\", payload.get(\"data\", [])[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390f5d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation OK ✅\n"
     ]
    }
   ],
   "source": [
    "# --- Step 2: Validate structure before writing ---\n",
    "columns = payload.get(\"columns\", [])\n",
    "data = payload.get(\"data\", [])\n",
    "\n",
    "assert \"Year\" in columns, \"Expected 'Year' in columns – check drilldowns=Year,Nation\"\n",
    "assert \"Nation\" in columns and \"Population\" in columns, \"Missing expected columns\"\n",
    "assert len(data) > 1, \"Expected multiple yearly rows; got a single row – check endpoint/params\"\n",
    "\n",
    "print(\"Validation OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40a3e439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote population_data.json with 10 rows\n"
     ]
    }
   ],
   "source": [
    "# --- Step 3: Save EXACT payload to local file (no transformation) ---\n",
    "LOCAL_JSON_PATH = \"population_data.json\"\n",
    "with open(LOCAL_JSON_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(payload, f, ensure_ascii=False, indent=2)\n",
    "print(f\"Wrote {LOCAL_JSON_PATH} with {len(data)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f88de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded s3://rearc-dataquest-harpreet/part2/population_data.json\n"
     ]
    }
   ],
   "source": [
    "# --- Step 4: Upload to S3 ---\n",
    "def upload_to_s3(local_path: str, bucket: str, key: str):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    with open(local_path, \"rb\") as fh:\n",
    "        s3.put_object(Bucket=bucket, Key=key, Body=fh, ContentType=\"application/json\")\n",
    "    print(f\"Uploaded s3://{bucket}/{key}\")\n",
    "\n",
    "try:\n",
    "    upload_to_s3(LOCAL_JSON_PATH, BUCKET_NAME, OBJECT_KEY)\n",
    "except ClientError as e:\n",
    "    print(\"S3 upload failed:\", e)\n",
    "    print(\"• Ensure AWS credentials are configured for the target account/region.\")\n",
    "    print(\"• Ensure bucket exists and you have PutObject permission.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128ad9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round-trip check OK ✅ (S3 content matches API payload)\n"
     ]
    }
   ],
   "source": [
    "# --- Optional: Download back from S3 and re-validate (read-after-write) ---\n",
    "def download_from_s3(bucket: str, key: str) -> Dict[str, Any]:\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "    return json.loads(obj[\"Body\"].read().decode(\"utf-8\"))\n",
    "\n",
    "try:\n",
    "    roundtrip = download_from_s3(BUCKET_NAME, OBJECT_KEY)\n",
    "    assert roundtrip == payload, \"Round-trip mismatch – uploaded content differs from API payload\"\n",
    "    print(\"Round-trip check OK (S3 content matches API payload)\")\n",
    "except ClientError as e:\n",
    "    print(\"S3 read-back skipped/failed (this is optional):\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ac464e",
   "metadata": {},
   "source": [
    "## Troubleshooting Notes\n",
    "- If your uploaded file still lacks `Year`, double-check:\n",
    "  - You are running **this** notebook (and not the older one).\n",
    "  - The `API_URL` path includes **`data.jsonrecords`** (plural) and **not** `data.json`.\n",
    "  - `API_PARAMS[\"drilldowns\"] == \"Year,Nation\"` exactly (order matters in the output columns).\n",
    "- If S3 upload fails, confirm:\n",
    "  - IAM user/role has `s3:PutObject` on the bucket/key.\n",
    "  - The bucket exists and is in your account (or correct cross-account policy is in place).\n",
    "  - Region is correct (set via AWS config or environment)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
